obs <- fts(x = mat.BB, y= yield_data[, obs_nr], xname = "Maturities", yname = "Yields")
curve_fpca <- 1
forc_FPCA_fts <- fts(x = mat.BB, y = data.frame(neat_tables[curve_fpca]), start = 1, xname = "Maturities", yname = "Forecasts")
########################
# Break up forecast matrices #
break_up_forc <- function(var_object, mat_vec, h=h) {
neat_forecasts <- matrix(0, nrow = length(mat_vec), ncol = h)
neat_tables <- list()
for (x in 1:ncol(var_object)) {
neat_forecasts <- matrix(var_object[,x], nrow = length(mat_vec), ncol = h)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_BB_PCA, mat_vec = mat.BB, h=4)
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply))
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
table_forecasting <- as.matrix(vapply(start:max_model, var_apply))
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply))
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
abort
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply))
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
end <- x + trainings_weeks -1
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply))
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply, FUN.VALUE = "matrix"))
return(table_forecasting)
}
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply, FUN.VALUE = "matrix"))
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply, c("First" = 0, "Last" = 0, "RMSE" = 0, "1_PCA_prop" = 0, "2_PCA_prop" = 0)))
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply, FUN.VALUE = matrix(NA, nrow = 3, ncol = 3)))
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
table_forecasting <- as.matrix(vapply(start:max_model, var_apply, FUN.VALUE = matrix(NA, nrow = 3, ncol = 3)))
return(table_forecasting)
}
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
list_forecasting <- lapply(start:max_model, var_apply)
table_forecasting <- do.call(rbind, list_forecasting)
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
write.csv(var_BB_PCA, file="var_BB_PCA_4_f3.txt")
########################
# Break up forecast matrices #
break_up_forc <- function(var_object, mat_vec, h=h) {
neat_forecasts <- matrix(0, nrow = length(mat_vec), ncol = h)
neat_tables <- list()
for (x in 1:ncol(var_object)) {
neat_forecasts <- matrix(var_object[,x], nrow = length(mat_vec), ncol = h)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_BB_PCA, mat_vec = mat.BB, h=4)
var_BB_PCA
# Observed yield curves #
obs_nr <- seq(from = 299, to = 300)
obs <- fts(x = mat.BB, y= yield_data[, obs_nr], xname = "Maturities", yname = "Yields")
curve_fpca <- 1
forc_FPCA_fts <- fts(x = mat.BB, y = data.frame(neat_tables[curve_fpca]), start = 1, xname = "Maturities", yname = "Forecasts")
plot(forc_FPCA_fts, ylab = "Yield curves", colorchoice = "rainbow", plotlegend = FALSE)
lines(obs, col="black")
forc_GP_BB_4 <- read.csv("BB_GPpred_estimates_4_(300).csv", header = FALSE, sep = ",")
forc_GP_BB_4[,1] <- NULL
forc_GP_BB_4 <- t(forc_GP_BB_4)
colnames(forc_GP_BB_4) <- seq(1:4)
forc_GP_BB_26 <- read.csv("BB_GPpred_estimates_26_(300).csv", header = FALSE, sep = ",")
forc_GP_BB_26[,1] <- NULL
forc_GP_BB_26 <- t(forc_GP_BB_26)
colnames(forc_GP_BB_26) <- seq(1:26)
forc_GP_BB_4_fts <- fts(x = mat.BB, y = forc_GP_BB_4, start = 1, xname = "Maturities", yname = "Forecasts")
########################
# Plot one forecast by FPCA #
fts_subset <- extract(BB_indx_fts, direction = "time", timeorder = 1:tw_var) # Subset data
fpca_model <- ftsm(y = fts_subset, order = 3, mean = TRUE, weight = FALSE)   # Generate FPCA model
ftsm_predict <- forecast.ftsm(fpca_model, h = 26, method = "arima")
plot(ftsm_predict$mean, ylab = "Yield curves", colorchoice = "rainbow", plotlegend = FALSE, ylim =c(-0.5,1.5), main="FPCA model for h=26")
lines(obs, col="black")
var_wrap_PCA <- function(trainings_weeks, fts_object, start, h, order_k, pred_method) {
if((start -1 + trainings_weeks + h) > ncol(fts_object$y)) stop("Too few curves in test data, reduce trainings_weeks or h")
max_model <- ncol(fts_object$y) - trainings_weeks - h +1
var_apply <- function(x) {
end <- x + trainings_weeks -1
fts_subset <- extract(fts_object, direction = "time", timeorder = x:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model - weights können hier generiert werden "weight = TRUE".
ftsm_predict <- forecast.ftsm(fpca_model, h = h, method = pred_method)   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = fts_object$y[, (end+1):(end+h)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- matrix(ftsm_predict$mean$y)
}
list_forecasting <- lapply(start:max_model, var_apply)
table_forecasting <- do.call(rbind, list_forecasting)
return(table_forecasting)
}
tw_var <- 300
var_BB_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = BB_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
write.csv(var_BB_PCA, file="var_BB_PCA_4_f3.txt")
########################
# Break up forecast matrices #
break_up_forc <- function(var_object, mat_vec, h=h) {
neat_forecasts <- matrix(0, nrow = length(mat_vec), ncol = h)
neat_tables <- list()
for (x in 1:ncol(var_object)) {
neat_forecasts <- matrix(var_object[,x], nrow = length(mat_vec), ncol = h)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_BB_PCA, mat_vec = mat.BB, h=4)
########################
# Break up forecast matrices #
break_up_forc <- function(var_object, mat_vec, h=h) {
neat_forecasts <- matrix(0, nrow = length(mat_vec), ncol = h)
neat_tables <- list()
for (x in 1:ncol(var_object)) {
neat_forecasts <- matrix(var_object[,x], nrow = length(mat_vec), ncol = h)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_BB_PCA, mat_vec = mat.BB, h=4)
var_US_PCA <- var_wrap_PCA(trainings_weeks = tw_var, fts_object = US_indx_fts, start = st, h = horizon, order_k = 3, pred_method = "arima")
write.csv(var_US_PCA, file="var_US_PCA_4_f3.txt")
########################
# Break up forecast matrices #
break_up_forc <- function(var_object, mat_vec, h=h) {
neat_forecasts <- matrix(0, nrow = length(mat_vec), ncol = h)
neat_tables <- list()
for (x in 1:ncol(var_object)) {
neat_forecasts <- matrix(var_object[,x], nrow = length(mat_vec), ncol = h)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_US_PCA, mat_vec = mat_US, h=4)
break_up_forc <- function(var_object, mat_vec, h=h) {
neat_forecasts <- matrix(0, nrow = length(mat_vec), ncol = h)
neat_tables <- list()
for (x in 1:ncol(var_object)) {
neat_forecasts <- matrix(var_object[,x], nrow = length(mat_vec), ncol = h)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_BB_PCA, mat_vec = mat.BB, h=4)
break_up_forc <- function(var_object, mat_vec, h = h) {
n_col <- ncol(var_object)
n_row <- length(mat_vec)
neat_tables <- list()
for (x in 1:n_col) {
neat_forecasts <- matrix(var_object[, x], nrow = n_row, ncol = h, byrow = TRUE)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_BB_PCA, mat_vec = mat.BB, h = 4)
break_up_forc <- function(var_object, mat_vec, h = h) {
n_col <- ncol(var_object)
n_row <- length(mat_vec)
neat_tables <- list()
for (x in 1:n_col) {
start_idx <- (x - 1) * n_row * h + 1
end_idx <- x * n_row * h
neat_forecasts <- matrix(var_object[start_idx:end_idx], nrow = n_row, ncol = h, byrow = TRUE)
colnames(neat_forecasts) <- seq(1:h)
rownames(neat_forecasts) <- mat_vec
neat_tables[[x]] <- neat_forecasts
}
return(neat_tables)
}
neat_tables <- break_up_forc(var_BB_PCA, mat_vec = mat.BB, h = 4)
#############################################
# FPCA: FPCs #
model_ftsm <- ftsm(y=BB_indx_fts, order = 3, mean = TRUE)
# Plot incl. coefficients #
plot.fm(model_ftsm, ylab1 = "Principal component",
xlab2 = "Periods", ylab2 = "Score", mean.lab = "Mean",
level.lab = "Level", main.title = "Main effects", interaction.title
= "Principal components", basiscol = "blue" , coeffcol = 1)   # 8x6.
model_ftsm_us <- ftsm(y=US_indx_fts, order = 3, mean = TRUE)
plot.fm(model_ftsm_us,  ylab1 = "Principal component",
xlab2 = "Periods", ylab2 = "Score", mean.lab = "Mean",
level.lab = "Level", main.title = "Main effects", interaction.title
= "Principal components", basiscol = "blue" , coeffcol = 1)   # 8x6.
plot.fm(model_ftsm_us,  ylab1 = "Principal component",
xlab2 = "Periods", ylab2 = "Score", mean.lab = "Mean",
level.lab = "Level", main.title = "Main effects", interaction.title
= "Principal components", basiscol = "cyan" , coeffcol = 1)   # 8x6.
plot.fm(model_ftsm_us,  ylab1 = "Principal component",
xlab2 = "Periods", ylab2 = "Score", mean.lab = "Mean",
level.lab = "Level", main.title = "Main effects", interaction.title
= "Principal components", basiscol = "red" , coeffcol = 1)   # 8x6.
# Plot incl. coefficients #
plot.fm(model_ftsm, ylab1 = "Principal component",
xlab2 = "Periods", ylab2 = "Score", mean.lab = "Mean",
level.lab = "Level", main.title = "Main effects", interaction.title
= "Principal components", basiscol = "red" , coeffcol = 1)   # 8x6.
plot.fm(model_ftsm_us,  ylab1 = "Principal component",
xlab2 = "Periods", ylab2 = "Score", mean.lab = "Mean",
level.lab = "Level", main.title = "Main effects", interaction.title
= "Principal components", basiscol = "red" , coeffcol = 1)   # 8x6.
plot(residuals(object = model_ftsm), type = "image", xlab = "Time", ylab = "Maturities")
plot(residuals(object = model_ftsm), type = "image", xlab = "Time", ylab = "Maturities")
plot(residuals(object = model_ftsm), type = "filled.contour", xlab = "Time", ylab = "Maturities")
plot(residuals(object = model_ftsm), type = "fts", xlab = "Time", ylab = "Maturities", plotlegend=TRUE)
plot(residuals(object = model_ftsm), type = "persp", xlab = "Time", ylab = "Maturities", col="red")
plot(residuals(object = model_ftsm_us), type = "persp", xlab = "Time", ylab = "Maturities", col="yellow")
plot(residuals(object = model_ftsm), type = "image", xlab = "Time", ylab = "Maturities")
plot(residuals(object = model_ftsm), type = "filled.contour", xlab = "Time", ylab = "Maturities")
plot(residuals(object = model_ftsm), type = "fts", xlab = "Time", ylab = "Maturities", plotlegend=TRUE)
plot(residuals(object = model_ftsm), type = "persp", xlab = "Time", ylab = "Maturities", col="red")
plot(residuals(object = model_ftsm_us), type = "persp", xlab = "Time", ylab = "Maturities", col="yellow")
plot(residuals(object = model_ftsm), type = "persp", xlab = "Time", ylab = "Maturities", col="yellow")
plot(residuals(object = model_ftsm_us), type = "persp", xlab = "Time", ylab = "Maturities", col="yellow")
plot(residuals(object = model_ftsm), type = "persp", xlab = "Time", ylab = "Maturities", col="red")
plot(residuals(object = model_ftsm), type = "persp", xlab = "Time", ylab = "Maturities", col="yellow")
plot(residuals(object = model_ftsm_us), type = "persp", xlab = "Time", ylab = "Maturities", col="yellow")
# Export data for Gaussian Processes in Python #
write.zoo(US_weekly, sep = ",")
write.csv(mat_US, row.names = FALSE)
# Export data for Gaussian Processes in Python #
write.zoo(BB_weekly, sep = ",")
write.csv(mat.BB, row.names = FALSE)
write.csv(mat.BB, "/Users/cemalozturk/Documents/DATA+/Ph.D/Thesis/tikV/Code/Py", row.names = FALSE)
# Export data for Gaussian Processes in Python #
write.zoo(BB_weekly, sep = ",")
write.csv(mat.BB, "/Users/cemalozturk/Documents/DATA+/Ph.D/Thesis/tikV/Code/Py/mat.BB.csv", row.names = FALSE)
# Export data for Gaussian Processes in Python #
write.zoo(BB_weekly, "/Users/cemalozturk/Documents/DATA+/Ph.D/Thesis/tikV/Code/Py/BB_weekly.csv", sep = ",")
# Export data for Gaussian Processes in Python #
write.zoo(US_weekly, "/Users/cemalozturk/Documents/DATA+/Ph.D/Thesis/tikV/Code/Py/US_weekly.csv", sep = ",")
write.csv(mat_US, "/Users/cemalozturk/Documents/DATA+/Ph.D/Thesis/tikV/Code/Py/mat.US.csv", row.names = FALSE)
View(US_raw_data)
View(BB_data)
end <- 300
horizon <- 26
st <- 1
# FPCA #
order_k <- 3
fts_subset <- extract(BB_indx_fts, direction = "time", timeorder = 1:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model
ftsm_predict <- forecast.ftsm(fpca_model, h = horizon, method = "arima")   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = BB_indx_fts$y[, (end+1):(end+horizon)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- c((end+1), (end+horizon), predict_error, fpca_model$varprop[1], fpca_model$varprop[2])
plot(y=BB_indx_fts$y[, (end+horizon)], x=mat.BB, type = "l")
lines(y=ftsm_predict$mean$y[,4], x=mat.BB, col="blue")
# DL #
order_p <- 1
#xtssubset <- BB_weekly[1:end]
xtssubset <- BB_weekly[1:end]                    # Subset data
est_parameters <- Nelson.Siegel(xtssubset, mat.BB)          # DL_model estimates parameters, takes most time.
# AR model and forecast parameters
arfit0 <- auto.arima(est_parameters$beta_0, max.p = order_p, max.q = 0, max.order = order_p, max.d = 0, max.D = 0,
ic = c("aic"), seasonal = FALSE, stepwise = TRUE)
arfit1 <- auto.arima(est_parameters$beta_1, max.p = order_p, max.q = 0, max.order = order_p, max.d = 0, max.D = 0,
ic = c("aic"), seasonal = FALSE, stepwise = TRUE)
arfit2 <- auto.arima(est_parameters$beta_2, max.p = order_p, max.q = 0, max.order = order_p, max.d = 0, max.D = 0,
ic = c("aic"), seasonal = FALSE, stepwise = TRUE)
for0 <- forecast(arfit0, h = horizon)
for1 <- forecast(arfit1, h = horizon)
for2 <- forecast(arfit2, h = horizon)
# Calculate nelsonsiegel_rates with forecasted parameters
NSparameter <- est_parameters[1:horizon]
NSparameter$beta_0 <- round(as.vector(for0$mean), 6)
NSparameter$beta_1 <- round(as.vector(for1$mean), 6)
NSparameter$beta_2 <- round(as.vector(for2$mean), 6)
NSparameter$lambda <- mean(est_parameters$lambda)
for_rates <- NSrates(NSparameter, mat.BB)
error_rates <- t(for_rates)
# Calculate errors
predict_error <- error(forecast = error_rates,
true = t(as.matrix(coredata(BB_weekly)[(end+1):(end+horizon),])), method = "rmse")
result <- c((end+1), (end+horizon), predict_error)
plot(y=t(as.matrix(coredata(BB_weekly)[(end+horizon),])), x=mat.BB, type = "l")
lines(y=error_rates[,4], x=mat.BB, col="blue")
plot(error_rates[,1], x=mat.BB, type = "l")
lines(y=error_rates[,2], x=mat.BB, col="blue")
lines(y=error_rates[,3], x=mat.BB, col="blue")
lines(y=error_rates[,4], x=mat.BB, col="blue")
curve_fpca <- 1
forc_FPCA_fts <- fts(x = mat.BB, y = data.frame(neat_tables[curve_fpca]), start = 1, xname = "Maturities", yname = "Forecasts")
plot(forc_FPCA_fts, ylab = "Yield curves", colorchoice = "rainbow", plotlegend = FALSE)
lines(obs, col="black")
curve_fpca <- 1
forc_FPCA_fts <- fts(x = mat.BB, y = data.frame(neat_tables[curve_fpca]), start = 1, xname = "Maturities", yname = "Forecasts")
plot(forc_FPCA_fts, ylab = "Yield curves", colorchoice = "rainbow", plotlegend = FALSE)
lines(obs, col="black")
obs_range_week <- c(1:length(neat_tables))
system.time({for(i in obs_range_week) {
forc_FPCA_fts <- fts(x = mat.BB, y = data.frame(neat_tables[i]), start = 1, xname = "Maturities", yname = "Forecasts")
plot(forc_FPCA_fts, ylab = paste("#", index[i+tw_var], sep=": "), colorchoice = "rainbow", ylim = c(-1,2))
title(main = "Yield curve forecasts")
grid()
Sys.sleep(0.05)
}
})
# Observed yield curves #
obs_nr <- seq(from = 299, to = 300)
obs <- fts(x = mat.BB, y= yield_data[, obs_nr], xname = "Maturities", yname = "Yields")
curve_fpca <- 1
forc_FPCA_fts <- fts(x = mat.BB, y = data.frame(neat_tables[curve_fpca]), start = 1, xname = "Maturities", yname = "Forecasts")
plot(forc_FPCA_fts, ylab = "Yield curves", colorchoice = "rainbow", plotlegend = FALSE)
lines(obs, col="black")
system.time({for(i in (obs_range_week+tw_var)) {
plot(x=mat.BB, y=BB_weekly[i,], type = "o", ylab=paste("#", index[i], sep=": "), ylim = c(-1,5))
#title(main = "Yield curve")
grid()
Sys.sleep(0.05)
}
})
fts_subset <- extract(BB_indx_fts, direction = "time", timeorder = 1:tw_var) # Subset data
fpca_model <- ftsm(y = fts_subset, order = 3, mean = TRUE, weight = FALSE)   # Generate FPCA model
ftsm_predict <- forecast.ftsm(fpca_model, h = 26, method = "arima")
plot(ftsm_predict$mean, ylab = "Yield curves", colorchoice = "rainbow", plotlegend = FALSE, ylim =c(-0.5,1.5), main="FPCA model for h=26")
lines(obs, col="black")
ggplot(plot.data_1, aes(range_tw_app)) +
geom_line(aes(y = dlbb4, colour = "BB", linetype = "BB")) + geom_line(aes(y = dlus4, colour = "US", linetype = "US")) +
scale_colour_manual("Legend", values=c("BB" = "blue", "US" = "black")) +
scale_linetype_manual("Legend", values=c("BB"=1, "US"=6)) +
theme(panel.border = element_rect(colour = "black", fill=NA, size=0.5)) +
coord_cartesian(ylim = c(0, 1)) +
labs(title = "Forecasting with Diebold-Li: influence of window size", x = 'Number of training data' , y = 'RMSE') +
theme(plot.title = element_text(size = '14', face = 'bold', hjust = 0.5)) +
theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
plot.data_1 = data.frame(cbind(dlbb4, dlus4, range_tw_app))
results_plots_app <- read.table("results_plots_appendix.csv", sep=";", header = FALSE)
#########################################
# DL  #
range_tw_app = seq(250,150,-30)
dlbb4 <- as.numeric(results_plots_app[5,2:5])
dlus4 <- as.numeric(results_plots_app[6,2:5])
dlbb26 <- as.numeric(results_plots_app[7,2:5])
dlus26 <- as.numeric(results_plots_app[8,2:5])
plot.data_1 = data.frame(cbind(dlbb4, dlus4, range_tw_app))
ggplot(plot.data_1, aes(range_tw_app)) +
geom_line(aes(y = dlbb4, colour = "BB", linetype = "BB")) + geom_line(aes(y = dlus4, colour = "US", linetype = "US")) +
scale_colour_manual("Legend", values=c("BB" = "blue", "US" = "black")) +
scale_linetype_manual("Legend", values=c("BB"=1, "US"=6)) +
theme(panel.border = element_rect(colour = "black", fill=NA, size=0.5)) +
coord_cartesian(ylim = c(0, 1)) +
labs(title = "Forecasting with Diebold-Li: influence of window size", x = 'Number of training data' , y = 'RMSE') +
theme(plot.title = element_text(size = '14', face = 'bold', hjust = 0.5)) +
theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
order_k <- 3
fts_subset <- extract(BB_indx_fts, direction = "time", timeorder = 1:end) # Subset data
fpca_model <- ftsm(y = fts_subset, order = order_k, mean = TRUE, weight = FALSE)   # Generate FPCA model
ftsm_predict <- forecast.ftsm(fpca_model, h = horizon, method = "arima")   # Generate forecasts based on the different models
predict_error <- error(forecast = ftsm_predict$mean$y,
true = BB_indx_fts$y[, (end+1):(end+horizon)], method = "rmse")    # Measuring prediction errors of interest rates in a curve combined.
result <- c((end+1), (end+horizon), predict_error, fpca_model$varprop[1], fpca_model$varprop[2])
plot(y=BB_indx_fts$y[, (end+horizon)], x=mat.BB, type = "l")
lines(y=ftsm_predict$mean$y[,4], x=mat.BB, col="blue")
